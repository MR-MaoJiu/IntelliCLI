"""
ä»£ç åˆ†æå·¥å…·
æä¾›ä»£ç æ¶æ„åˆ†æã€ä¾èµ–åˆ†æã€è´¨é‡æ£€æŸ¥ç­‰åŠŸèƒ½
"""

import os
import ast
import json
import re
from typing import Dict, List, Set, Any
from collections import defaultdict
import subprocess

# å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯å˜é‡
_global_model_client = None

def set_model_client(model_client):
    """è®¾ç½®å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯"""
    global _global_model_client
    _global_model_client = model_client

def get_model_client():
    """è·å–å½“å‰çš„æ¨¡å‹å®¢æˆ·ç«¯"""
    return _global_model_client

class CodeAnalyzer:
    """ä»£ç åˆ†æå·¥å…·ç±»"""
    
    def __init__(self, project_root: str):
        self.project_root = project_root
        self.model_client = None
        self.supported_extensions = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.go': 'go',
            '.rs': 'rust',
            '.php': 'php',
            '.rb': 'ruby',
            '.html': 'html',
            '.css': 'css',
            '.sql': 'sql'
        }

    def set_model_client(self, model_client):
        """è®¾ç½®ä»£ç åˆ†æä½¿ç”¨çš„æ¨¡å‹å®¢æˆ·ç«¯"""
        self.model_client = model_client

    def analyze_project_structure(self) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®æ¶æ„"""
        structure = {
            'directories': [],
            'files': {},
            'language_stats': {},
            'total_files': 0,
            'total_lines': 0
        }
        
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡éšè—ç›®å½•å’Œå¸¸è§çš„å¿½ç•¥ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv', 'env']]
            
            rel_root = os.path.relpath(root, self.project_root)
            if rel_root != '.':
                structure['directories'].append(rel_root)
            
            for file in files:
                if file.startswith('.'):
                    continue
                    
                file_path = os.path.join(root, file)
                rel_path = os.path.relpath(file_path, self.project_root)
                
                # è·å–æ–‡ä»¶æ‰©å±•å
                _, ext = os.path.splitext(file)
                if ext:
                    ext = ext.lower()
                    structure['language_stats'][ext] = structure['language_stats'].get(ext, 0) + 1
                
                # ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = len(f.readlines())
                        structure['files'][rel_path] = {
                            'extension': ext,
                            'lines': lines,
                            'size': os.path.getsize(file_path)
                        }
                        structure['total_lines'] += lines
                        structure['total_files'] += 1
                except:
                    pass
        
        return structure
    
    def analyze_python_dependencies(self) -> Dict[str, List[str]]:
        """åˆ†æPythonä¾èµ–å…³ç³»"""
        dependencies = defaultdict(list)
        
        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'venv', 'env']]
            
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    rel_path = os.path.relpath(file_path, self.project_root)
                    
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        tree = ast.parse(content)
                        
                        for node in ast.walk(tree):
                            if isinstance(node, ast.Import):
                                for alias in node.names:
                                    dependencies[rel_path].append(alias.name)
                            elif isinstance(node, ast.ImportFrom):
                                if node.module:
                                    dependencies[rel_path].append(node.module)
                                    
                    except Exception as e:
                        dependencies[rel_path].append(f"Error parsing: {e}")
        
        return dict(dependencies)
    
    def analyze_code_quality(self, file_path: str) -> Dict[str, Any]:
        """åˆ†æä»£ç è´¨é‡"""
        quality_report = {
            'file': file_path,
            'issues': [],
            'metrics': {},
            'suggestions': []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            # åŸºç¡€æŒ‡æ ‡
            quality_report['metrics'] = {
                'lines_of_code': len(lines),
                'empty_lines': sum(1 for line in lines if not line.strip()),
                'comment_lines': sum(1 for line in lines if line.strip().startswith('#')),
                'avg_line_length': sum(len(line) for line in lines) / len(lines) if lines else 0
            }
            
            # ä»£ç è´¨é‡æ£€æŸ¥
            if file_path.endswith('.py'):
                quality_report.update(self._analyze_python_quality(content, lines))
            elif file_path.endswith('.js'):
                quality_report.update(self._analyze_js_quality(content, lines))
                
        except Exception as e:
            quality_report['issues'].append(f"Error analyzing file: {e}")
        
        return quality_report
    
    def _analyze_python_quality(self, content: str, lines: List[str]) -> Dict[str, Any]:
        """åˆ†æPythonä»£ç è´¨é‡"""
        issues = []
        suggestions = []
        
        try:
            tree = ast.parse(content)
            
            # æ£€æŸ¥å‡½æ•°å’Œç±»
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    # æ£€æŸ¥å‡½æ•°é•¿åº¦
                    func_lines = node.end_lineno - node.lineno + 1
                    if func_lines > 50:
                        issues.append(f"Function '{node.name}' is too long ({func_lines} lines)")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£å­—ç¬¦ä¸²
                    if not ast.get_docstring(node):
                        suggestions.append(f"Add docstring to function '{node.name}'")
                        
                elif isinstance(node, ast.ClassDef):
                    # æ£€æŸ¥ç±»æ–‡æ¡£å­—ç¬¦ä¸²
                    if not ast.get_docstring(node):
                        suggestions.append(f"Add docstring to class '{node.name}'")
            
            # æ£€æŸ¥ä»£ç é£æ ¼
            for i, line in enumerate(lines, 1):
                if len(line) > 100:
                    issues.append(f"Line {i} is too long ({len(line)} characters)")
                    
        except SyntaxError as e:
            issues.append(f"Syntax error: {e}")
        except Exception as e:
            issues.append(f"Analysis error: {e}")
        
        return {'issues': issues, 'suggestions': suggestions}
    
    def _analyze_js_quality(self, content: str, lines: List[str]) -> Dict[str, Any]:
        """åˆ†æJavaScriptä»£ç è´¨é‡"""
        issues = []
        suggestions = []
        
        # åŸºç¡€JavaScriptè´¨é‡æ£€æŸ¥
        for i, line in enumerate(lines, 1):
            if len(line) > 120:
                issues.append(f"Line {i} is too long ({len(line)} characters)")
            
            # æ£€æŸ¥å¸¸è§é—®é¢˜
            if '==' in line and '===' not in line:
                suggestions.append(f"Line {i}: Consider using '===' instead of '=='")
            
            if 'var ' in line:
                suggestions.append(f"Line {i}: Consider using 'let' or 'const' instead of 'var'")
        
        return {'issues': issues, 'suggestions': suggestions}
    
    def find_security_issues(self, file_path: str) -> List[Dict[str, str]]:
        """æŸ¥æ‰¾å®‰å…¨é—®é¢˜"""
        security_issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å¸¸è§å®‰å…¨é—®é¢˜æ¨¡å¼
            security_patterns = [
                (r'eval\s*\(', 'Potential code injection vulnerability with eval()'),
                (r'exec\s*\(', 'Potential code injection vulnerability with exec()'),
                (r'os\.system\s*\(', 'Potential command injection vulnerability'),
                (r'subprocess\.call\s*\([^)]*shell\s*=\s*True', 'Command injection risk with shell=True'),
                (r'password\s*=\s*["\'][^"\']*["\']', 'Hardcoded password detected'),
                (r'api_key\s*=\s*["\'][^"\']*["\']', 'Hardcoded API key detected'),
                (r'secret\s*=\s*["\'][^"\']*["\']', 'Hardcoded secret detected'),
            ]
            
            for pattern, description in security_patterns:
                matches = re.finditer(pattern, content, re.IGNORECASE)
                for match in matches:
                    line_no = content[:match.start()].count('\n') + 1
                    security_issues.append({
                        'file': file_path,
                        'line': line_no,
                        'issue': description,
                        'code': match.group(0)
                    })
                    
        except Exception as e:
            security_issues.append({
                'file': file_path,
                'line': 0,
                'issue': f'Error analyzing file: {e}',
                'code': ''
            })
        
        return security_issues

    def analyze_code_with_ai(self, file_path: str, analysis_type: str = "general") -> str:
        """ä½¿ç”¨AIæ¨¡å‹åˆ†æä»£ç """
        model_client = _global_model_client or self.model_client
        
        if not model_client:
            return "æœªè®¾ç½®æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ— æ³•è¿›è¡ŒAIä»£ç åˆ†æ"
        
        if not os.path.exists(file_path):
            return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                code_content = f.read()
            
            # è·å–æ–‡ä»¶æ‰©å±•åå’Œè¯­è¨€ç±»å‹
            _, ext = os.path.splitext(file_path)
            language = self.supported_extensions.get(ext.lower(), 'unknown')
            
            # æ„å»ºåˆ†ææç¤º
            analysis_prompts = {
                "general": f"""
                è¯·åˆ†æä»¥ä¸‹{language}ä»£ç ï¼Œæä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š
                1. ä»£ç åŠŸèƒ½å’Œç›®çš„
                2. ä»£ç ç»“æ„å’Œç»„ç»‡
                3. å…³é”®å‡½æ•°å’Œç±»çš„è¯´æ˜
                4. ä»£ç è´¨é‡è¯„ä¼°
                5. æ½œåœ¨çš„æ”¹è¿›å»ºè®®
                
                æ–‡ä»¶è·¯å¾„: {file_path}
                ä»£ç å†…å®¹:
                {code_content}
                """,
                "quality": f"""
                è¯·ä»ä»£ç è´¨é‡è§’åº¦åˆ†æä»¥ä¸‹{language}ä»£ç ï¼š
                1. ä»£ç å¯è¯»æ€§
                2. æ€§èƒ½ä¼˜åŒ–å»ºè®®
                3. é”™è¯¯å¤„ç†
                4. ä»£ç é‡æ„å»ºè®®
                5. æœ€ä½³å®è·µéµå¾ªæƒ…å†µ
                
                æ–‡ä»¶è·¯å¾„: {file_path}
                ä»£ç å†…å®¹:
                {code_content}
                """,
                "security": f"""
                è¯·ä»å®‰å…¨è§’åº¦åˆ†æä»¥ä¸‹{language}ä»£ç ï¼š
                1. æ½œåœ¨çš„å®‰å…¨æ¼æ´
                2. è¾“å…¥éªŒè¯é—®é¢˜
                3. æƒé™æ§åˆ¶é—®é¢˜
                4. æ•°æ®æ³„éœ²é£é™©
                5. å®‰å…¨ä¿®å¤å»ºè®®
                
                æ–‡ä»¶è·¯å¾„: {file_path}
                ä»£ç å†…å®¹:
                {code_content}
                """,
                "performance": f"""
                è¯·ä»æ€§èƒ½è§’åº¦åˆ†æä»¥ä¸‹{language}ä»£ç ï¼š
                1. æ€§èƒ½ç“¶é¢ˆè¯†åˆ«
                2. ç®—æ³•å¤æ‚åº¦åˆ†æ
                3. å†…å­˜ä½¿ç”¨ä¼˜åŒ–
                4. å¹¶å‘æ€§èƒ½è€ƒè™‘
                5. æ€§èƒ½ä¼˜åŒ–å»ºè®®
                
                æ–‡ä»¶è·¯å¾„: {file_path}
                ä»£ç å†…å®¹:
                {code_content}
                """
            }
            
            prompt = analysis_prompts.get(analysis_type, analysis_prompts["general"])
            return model_client.generate(prompt)
            
        except Exception as e:
            return f"åˆ†æä»£ç æ—¶å‡ºé”™: {e}"

    def generate_code_documentation(self, file_path: str) -> str:
        """ç”Ÿæˆä»£ç æ–‡æ¡£"""
        model_client = _global_model_client or self.model_client
        
        if not model_client:
            return "æœªè®¾ç½®æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ— æ³•ç”Ÿæˆä»£ç æ–‡æ¡£"
        
        if not os.path.exists(file_path):
            return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                code_content = f.read()
            
            _, ext = os.path.splitext(file_path)
            language = self.supported_extensions.get(ext.lower(), 'unknown')
            
            prompt = f"""
            è¯·ä¸ºä»¥ä¸‹{language}ä»£ç ç”Ÿæˆè¯¦ç»†çš„æ–‡æ¡£ï¼š
            
            æ–‡ä»¶è·¯å¾„: {file_path}
            ä»£ç å†…å®¹:
            {code_content}
            
            è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹å†…å®¹çš„æ–‡æ¡£ï¼š
            1. æ–‡ä»¶æ¦‚è¿°å’Œç›®çš„
            2. ä¾èµ–é¡¹å’Œå¯¼å…¥è¯´æ˜
            3. å‡½æ•°å’Œç±»çš„è¯¦ç»†è¯´æ˜
            4. å‚æ•°å’Œè¿”å›å€¼è¯´æ˜
            5. ä½¿ç”¨ç¤ºä¾‹
            6. æ³¨æ„äº‹é¡¹å’Œé™åˆ¶
            
            è¯·ä½¿ç”¨Markdownæ ¼å¼ï¼Œå¹¶ç¡®ä¿æ–‡æ¡£æ¸…æ™°æ˜“æ‡‚ã€‚
            """
            
            return model_client.generate(prompt)
            
        except Exception as e:
            return f"ç”Ÿæˆä»£ç æ–‡æ¡£æ—¶å‡ºé”™: {e}"

    def suggest_code_improvements(self, file_path: str) -> str:
        """å»ºè®®ä»£ç æ”¹è¿›"""
        model_client = _global_model_client or self.model_client
        
        if not model_client:
            return "æœªè®¾ç½®æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ— æ³•æä¾›ä»£ç æ”¹è¿›å»ºè®®"
        
        if not os.path.exists(file_path):
            return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                code_content = f.read()
            
            _, ext = os.path.splitext(file_path)
            language = self.supported_extensions.get(ext.lower(), 'unknown')
            
            prompt = f"""
            è¯·ä¸ºä»¥ä¸‹{language}ä»£ç æä¾›æ”¹è¿›å»ºè®®ï¼š
            
            æ–‡ä»¶è·¯å¾„: {file_path}
            ä»£ç å†…å®¹:
            {code_content}
            
            è¯·æä¾›ï¼š
            1. å…·ä½“çš„æ”¹è¿›å»ºè®®
            2. æ”¹è¿›å‰åçš„ä»£ç å¯¹æ¯”
            3. æ”¹è¿›ç†ç”±å’Œå¥½å¤„
            4. å®æ–½éš¾åº¦è¯„ä¼°
            5. ä¼˜å…ˆçº§å»ºè®®
            
            è¯·é‡ç‚¹å…³æ³¨ï¼š
            - ä»£ç å¯è¯»æ€§å’Œç»´æŠ¤æ€§
            - æ€§èƒ½ä¼˜åŒ–
            - é”™è¯¯å¤„ç†
            - ä»£ç é‡æ„
            - æœ€ä½³å®è·µ
            """
            
            return model_client.generate(prompt)
            
        except Exception as e:
            return f"ç”Ÿæˆä»£ç æ”¹è¿›å»ºè®®æ—¶å‡ºé”™: {e}"

    def explain_code_logic(self, file_path: str) -> str:
        """è§£é‡Šä»£ç é€»è¾‘"""
        model_client = _global_model_client or self.model_client
        
        if not model_client:
            return "æœªè®¾ç½®æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ— æ³•è§£é‡Šä»£ç é€»è¾‘"
        
        if not os.path.exists(file_path):
            return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                code_content = f.read()
            
            _, ext = os.path.splitext(file_path)
            language = self.supported_extensions.get(ext.lower(), 'unknown')
            
            prompt = f"""
            è¯·è¯¦ç»†è§£é‡Šä»¥ä¸‹{language}ä»£ç çš„é€»è¾‘ï¼š
            
            æ–‡ä»¶è·¯å¾„: {file_path}
            ä»£ç å†…å®¹:
            {code_content}
            
            è¯·æä¾›ï¼š
            1. ä»£ç çš„æ•´ä½“æ‰§è¡Œæµç¨‹
            2. å…³é”®ç®—æ³•å’Œæ•°æ®ç»“æ„çš„è§£é‡Š
            3. å„ä¸ªå‡½æ•°å’Œç±»çš„ä½œç”¨
            4. ä»£ç çš„è®¾è®¡æ€è·¯
            5. ä¸å…¶ä»–æ¨¡å—çš„äº¤äº’æ–¹å¼
            
            è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šï¼Œé€‚åˆä¸åŒæŠ€æœ¯æ°´å¹³çš„è¯»è€…ã€‚
            """
            
            return model_client.generate(prompt)
            
        except Exception as e:
            return f"è§£é‡Šä»£ç é€»è¾‘æ—¶å‡ºé”™: {e}"

def analyze_project_structure(project_path: str) -> str:
    """åˆ†æé¡¹ç›®ç»“æ„"""
    try:
        analyzer = CodeAnalyzer(project_path)
        structure = analyzer.analyze_project_structure()
        
        result = f"ğŸ“Š é¡¹ç›®ç»“æ„åˆ†ææŠ¥å‘Š\n"
        result += f"{'='*50}\n\n"
        result += f"ğŸ“ æ€»æ–‡ä»¶æ•°: {structure['total_files']}\n"
        result += f"ğŸ“„ æ€»ä»£ç è¡Œæ•°: {structure['total_lines']}\n"
        result += f"ğŸ“‚ ç›®å½•æ•°: {len(structure['directories'])}\n\n"
        
        result += f"ğŸ”¤ è¯­è¨€ç»Ÿè®¡:\n"
        for ext, count in sorted(structure['language_stats'].items()):
            result += f"  {ext}: {count} ä¸ªæ–‡ä»¶\n"
        
        result += f"\nğŸ“‚ ç›®å½•ç»“æ„:\n"
        for directory in sorted(structure['directories']):
            result += f"  {directory}/\n"
        
        return result
        
    except Exception as e:
        return f"âŒ åˆ†æé¡¹ç›®ç»“æ„æ—¶å‡ºé”™: {e}"

def analyze_python_dependencies(project_path: str) -> str:
    """åˆ†æPythonä¾èµ–å…³ç³»"""
    try:
        analyzer = CodeAnalyzer(project_path)
        dependencies = analyzer.analyze_python_dependencies()
        
        result = f"ğŸ”— Pythonä¾èµ–å…³ç³»åˆ†æ\n"
        result += f"{'='*50}\n\n"
        
        for file_path, deps in dependencies.items():
            result += f"ğŸ“„ {file_path}:\n"
            for dep in deps:
                result += f"  â””â”€â”€ {dep}\n"
            result += "\n"
        
        return result
        
    except Exception as e:
        return f"âŒ åˆ†æä¾èµ–å…³ç³»æ—¶å‡ºé”™: {e}"

# å¢å¼ºçš„ä»£ç åˆ†æå‡½æ•°
def analyze_code_quality(file_path: str) -> str:
    """åˆ†æä»£ç è´¨é‡"""
    analyzer = CodeAnalyzer(os.path.dirname(file_path))
    
    # ä½¿ç”¨å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯
    model_client = get_model_client()
    if model_client:
        analyzer.set_model_client(model_client)
        # ä½¿ç”¨AIåˆ†æ
        ai_analysis = analyzer.analyze_code_with_ai(file_path, "quality")
        return ai_analysis
    
    # å¦‚æœæ²¡æœ‰æ¨¡å‹å®¢æˆ·ç«¯ï¼Œä½¿ç”¨åŸæœ‰çš„é™æ€åˆ†æ
    if not os.path.exists(file_path):
        return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
    
    try:
        analysis = analyzer.analyze_code_quality(file_path)
        
        result = f"ä»£ç è´¨é‡åˆ†ææŠ¥å‘Š: {file_path}\n"
        result += "=" * 50 + "\n\n"
        
        # åŸºæœ¬ä¿¡æ¯
        result += f"æ–‡ä»¶å¤§å°: {analysis['file_size']} å­—èŠ‚\n"
        result += f"ä»£ç è¡Œæ•°: {analysis['line_count']} è¡Œ\n"
        result += f"ç©ºè¡Œæ•°: {analysis['blank_lines']} è¡Œ\n"
        result += f"æ³¨é‡Šè¡Œæ•°: {analysis['comment_lines']} è¡Œ\n"
        result += f"ä»£ç å¯†åº¦: {analysis['code_density']:.1%}\n\n"
        
        # è´¨é‡æŒ‡æ ‡
        result += "è´¨é‡æŒ‡æ ‡:\n"
        for metric, value in analysis['quality_metrics'].items():
            result += f"  {metric}: {value}\n"
        
        # é—®é¢˜åˆ—è¡¨
        if analysis['issues']:
            result += f"\nå‘ç°çš„é—®é¢˜ ({len(analysis['issues'])} ä¸ª):\n"
            for issue in analysis['issues']:
                result += f"  - è¡Œ {issue['line']}: {issue['message']}\n"
        
        # å»ºè®®
        if analysis['suggestions']:
            result += f"\næ”¹è¿›å»ºè®®:\n"
            for suggestion in analysis['suggestions']:
                result += f"  - {suggestion}\n"
        
        return result
        
    except Exception as e:
        return f"åˆ†æä»£ç è´¨é‡æ—¶å‡ºé”™: {e}"

def find_security_issues(file_path: str) -> str:
    """æŸ¥æ‰¾å®‰å…¨é—®é¢˜"""
    analyzer = CodeAnalyzer(os.path.dirname(file_path))
    
    # ä½¿ç”¨å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯
    model_client = get_model_client()
    if model_client:
        analyzer.set_model_client(model_client)
        # ä½¿ç”¨AIåˆ†æå®‰å…¨é—®é¢˜
        ai_analysis = analyzer.analyze_code_with_ai(file_path, "security")
        return ai_analysis
    
    # å¦‚æœæ²¡æœ‰æ¨¡å‹å®¢æˆ·ç«¯ï¼Œä½¿ç”¨åŸæœ‰çš„é™æ€åˆ†æ
    if not os.path.exists(file_path):
        return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
    
    try:
        issues = analyzer.find_security_issues(file_path)
        
        if not issues:
            return f"âœ… æœªå‘ç°æ˜æ˜¾çš„å®‰å…¨é—®é¢˜: {file_path}"
        
        result = f"ğŸ”’ å®‰å…¨é—®é¢˜åˆ†æ: {file_path}\n"
        result += "=" * 50 + "\n\n"
        result += f"å‘ç° {len(issues)} ä¸ªæ½œåœ¨å®‰å…¨é—®é¢˜:\n\n"
        
        for i, issue in enumerate(issues, 1):
            result += f"{i}. {issue['type']}\n"
            result += f"   ä½ç½®: è¡Œ {issue['line']}\n"
            result += f"   æè¿°: {issue['description']}\n"
            result += f"   é£é™©ç­‰çº§: {issue['risk_level']}\n\n"
        
        return result
        
    except Exception as e:
        return f"æŸ¥æ‰¾å®‰å…¨é—®é¢˜æ—¶å‡ºé”™: {e}"

def generate_code_documentation(file_path: str) -> str:
    """ç”Ÿæˆä»£ç æ–‡æ¡£"""
    analyzer = CodeAnalyzer(os.path.dirname(file_path))
    
    # ä½¿ç”¨å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯
    model_client = get_model_client()
    if model_client:
        analyzer.set_model_client(model_client)
        return analyzer.generate_code_documentation(file_path)
    
    return "æœªè®¾ç½®æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ— æ³•ç”Ÿæˆä»£ç æ–‡æ¡£"

def suggest_code_improvements(file_path: str) -> str:
    """å»ºè®®ä»£ç æ”¹è¿›"""
    analyzer = CodeAnalyzer(os.path.dirname(file_path))
    
    # ä½¿ç”¨å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯
    model_client = get_model_client()
    if model_client:
        analyzer.set_model_client(model_client)
        return analyzer.suggest_code_improvements(file_path)
    
    return "æœªè®¾ç½®æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ— æ³•æä¾›ä»£ç æ”¹è¿›å»ºè®®"

def explain_code_logic(file_path: str) -> str:
    """è§£é‡Šä»£ç é€»è¾‘"""
    analyzer = CodeAnalyzer(os.path.dirname(file_path))
    
    # ä½¿ç”¨å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯
    model_client = get_model_client()
    if model_client:
        analyzer.set_model_client(model_client)
        return analyzer.explain_code_logic(file_path)
    
    return "æœªè®¾ç½®æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ— æ³•è§£é‡Šä»£ç é€»è¾‘"

def analyze_code_performance(file_path: str) -> str:
    """åˆ†æä»£ç æ€§èƒ½"""
    analyzer = CodeAnalyzer(os.path.dirname(file_path))
    
    # ä½¿ç”¨å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯
    model_client = get_model_client()
    if model_client:
        analyzer.set_model_client(model_client)
        return analyzer.analyze_code_with_ai(file_path, "performance")
    
    return "æœªè®¾ç½®æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ— æ³•åˆ†æä»£ç æ€§èƒ½"

def review_code_architecture(project_path: str) -> str:
    """å®¡æŸ¥ä»£ç æ¶æ„"""
    analyzer = CodeAnalyzer(project_path)
    
    # ä½¿ç”¨å…¨å±€æ¨¡å‹å®¢æˆ·ç«¯
    model_client = get_model_client()
    if model_client:
        analyzer.set_model_client(model_client)
        
        try:
            # è·å–é¡¹ç›®ç»“æ„
            structure_info = analyzer.analyze_project_structure()
            
            # åˆ†æä¾èµ–å…³ç³»
            dependency_info = analyzer.analyze_python_dependencies()
            
            # æ„å»ºæ¶æ„å®¡æŸ¥æç¤º
            prompt = f"""
            è¯·å®¡æŸ¥ä»¥ä¸‹é¡¹ç›®çš„ä»£ç æ¶æ„ï¼š
            
            é¡¹ç›®è·¯å¾„: {project_path}
            
            é¡¹ç›®ç»“æ„ä¿¡æ¯:
            {structure_info}
            
            ä¾èµ–å…³ç³»ä¿¡æ¯:
            {dependency_info}
            
            è¯·æä¾›ï¼š
            1. æ¶æ„æ¨¡å¼åˆ†æ
            2. æ¨¡å—è€¦åˆåº¦è¯„ä¼°
            3. ä»£ç ç»„ç»‡åˆç†æ€§
            4. æ¶æ„ä¼˜åŒ–å»ºè®®
            5. æŠ€æœ¯æ ˆè¯„ä¼°
            6. å¯ç»´æŠ¤æ€§åˆ†æ
            
            è¯·ä»è½¯ä»¶æ¶æ„å¸ˆçš„è§’åº¦æä¾›ä¸“ä¸šå»ºè®®ã€‚
            """
            
            return model_client.generate(prompt)
            
        except Exception as e:
            return f"å®¡æŸ¥ä»£ç æ¶æ„æ—¶å‡ºé”™: {e}"
    
    return "æœªè®¾ç½®æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ— æ³•å®¡æŸ¥ä»£ç æ¶æ„" 