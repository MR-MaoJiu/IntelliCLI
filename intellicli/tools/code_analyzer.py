"""
ä»£ç åˆ†æå·¥å…·
æä¾›ä»£ç æ¶æ„åˆ†æã€ä¾èµ–åˆ†æã€è´¨é‡æ£€æŸ¥ç­‰åŠŸèƒ½
"""

import os
import ast
import json
import re
from typing import Dict, List, Set, Any
from collections import defaultdict
import subprocess

class CodeAnalyzer:
    """ä»£ç åˆ†æå™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = project_root
        self.python_files = []
        self.js_files = []
        self.dependencies = defaultdict(set)
        self.functions = []
        self.classes = []
        
    def analyze_project_structure(self) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®æ¶æ„"""
        structure = {
            'directories': [],
            'files': {},
            'language_stats': {},
            'total_files': 0,
            'total_lines': 0
        }
        
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡éšè—ç›®å½•å’Œå¸¸è§çš„å¿½ç•¥ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv', 'env']]
            
            rel_root = os.path.relpath(root, self.project_root)
            if rel_root != '.':
                structure['directories'].append(rel_root)
            
            for file in files:
                if file.startswith('.'):
                    continue
                    
                file_path = os.path.join(root, file)
                rel_path = os.path.relpath(file_path, self.project_root)
                
                # è·å–æ–‡ä»¶æ‰©å±•å
                _, ext = os.path.splitext(file)
                if ext:
                    ext = ext.lower()
                    structure['language_stats'][ext] = structure['language_stats'].get(ext, 0) + 1
                
                # ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = len(f.readlines())
                        structure['files'][rel_path] = {
                            'extension': ext,
                            'lines': lines,
                            'size': os.path.getsize(file_path)
                        }
                        structure['total_lines'] += lines
                        structure['total_files'] += 1
                except:
                    pass
        
        return structure
    
    def analyze_python_dependencies(self) -> Dict[str, List[str]]:
        """åˆ†æPythonä¾èµ–å…³ç³»"""
        dependencies = defaultdict(list)
        
        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'venv', 'env']]
            
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    rel_path = os.path.relpath(file_path, self.project_root)
                    
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        tree = ast.parse(content)
                        
                        for node in ast.walk(tree):
                            if isinstance(node, ast.Import):
                                for alias in node.names:
                                    dependencies[rel_path].append(alias.name)
                            elif isinstance(node, ast.ImportFrom):
                                if node.module:
                                    dependencies[rel_path].append(node.module)
                                    
                    except Exception as e:
                        dependencies[rel_path].append(f"Error parsing: {e}")
        
        return dict(dependencies)
    
    def analyze_code_quality(self, file_path: str) -> Dict[str, Any]:
        """åˆ†æä»£ç è´¨é‡"""
        quality_report = {
            'file': file_path,
            'issues': [],
            'metrics': {},
            'suggestions': []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            # åŸºç¡€æŒ‡æ ‡
            quality_report['metrics'] = {
                'lines_of_code': len(lines),
                'empty_lines': sum(1 for line in lines if not line.strip()),
                'comment_lines': sum(1 for line in lines if line.strip().startswith('#')),
                'avg_line_length': sum(len(line) for line in lines) / len(lines) if lines else 0
            }
            
            # ä»£ç è´¨é‡æ£€æŸ¥
            if file_path.endswith('.py'):
                quality_report.update(self._analyze_python_quality(content, lines))
            elif file_path.endswith('.js'):
                quality_report.update(self._analyze_js_quality(content, lines))
                
        except Exception as e:
            quality_report['issues'].append(f"Error analyzing file: {e}")
        
        return quality_report
    
    def _analyze_python_quality(self, content: str, lines: List[str]) -> Dict[str, Any]:
        """åˆ†æPythonä»£ç è´¨é‡"""
        issues = []
        suggestions = []
        
        try:
            tree = ast.parse(content)
            
            # æ£€æŸ¥å‡½æ•°å’Œç±»
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    # æ£€æŸ¥å‡½æ•°é•¿åº¦
                    func_lines = node.end_lineno - node.lineno + 1
                    if func_lines > 50:
                        issues.append(f"Function '{node.name}' is too long ({func_lines} lines)")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£å­—ç¬¦ä¸²
                    if not ast.get_docstring(node):
                        suggestions.append(f"Add docstring to function '{node.name}'")
                        
                elif isinstance(node, ast.ClassDef):
                    # æ£€æŸ¥ç±»æ–‡æ¡£å­—ç¬¦ä¸²
                    if not ast.get_docstring(node):
                        suggestions.append(f"Add docstring to class '{node.name}'")
            
            # æ£€æŸ¥ä»£ç é£æ ¼
            for i, line in enumerate(lines, 1):
                if len(line) > 100:
                    issues.append(f"Line {i} is too long ({len(line)} characters)")
                    
        except SyntaxError as e:
            issues.append(f"Syntax error: {e}")
        except Exception as e:
            issues.append(f"Analysis error: {e}")
        
        return {'issues': issues, 'suggestions': suggestions}
    
    def _analyze_js_quality(self, content: str, lines: List[str]) -> Dict[str, Any]:
        """åˆ†æJavaScriptä»£ç è´¨é‡"""
        issues = []
        suggestions = []
        
        # åŸºç¡€JavaScriptè´¨é‡æ£€æŸ¥
        for i, line in enumerate(lines, 1):
            if len(line) > 120:
                issues.append(f"Line {i} is too long ({len(line)} characters)")
            
            # æ£€æŸ¥å¸¸è§é—®é¢˜
            if '==' in line and '===' not in line:
                suggestions.append(f"Line {i}: Consider using '===' instead of '=='")
            
            if 'var ' in line:
                suggestions.append(f"Line {i}: Consider using 'let' or 'const' instead of 'var'")
        
        return {'issues': issues, 'suggestions': suggestions}
    
    def find_security_issues(self, file_path: str) -> List[Dict[str, str]]:
        """æŸ¥æ‰¾å®‰å…¨é—®é¢˜"""
        security_issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å¸¸è§å®‰å…¨é—®é¢˜æ¨¡å¼
            security_patterns = [
                (r'eval\s*\(', 'Potential code injection vulnerability with eval()'),
                (r'exec\s*\(', 'Potential code injection vulnerability with exec()'),
                (r'os\.system\s*\(', 'Potential command injection vulnerability'),
                (r'subprocess\.call\s*\([^)]*shell\s*=\s*True', 'Command injection risk with shell=True'),
                (r'password\s*=\s*["\'][^"\']*["\']', 'Hardcoded password detected'),
                (r'api_key\s*=\s*["\'][^"\']*["\']', 'Hardcoded API key detected'),
                (r'secret\s*=\s*["\'][^"\']*["\']', 'Hardcoded secret detected'),
            ]
            
            for pattern, description in security_patterns:
                matches = re.finditer(pattern, content, re.IGNORECASE)
                for match in matches:
                    line_no = content[:match.start()].count('\n') + 1
                    security_issues.append({
                        'file': file_path,
                        'line': line_no,
                        'issue': description,
                        'code': match.group(0)
                    })
                    
        except Exception as e:
            security_issues.append({
                'file': file_path,
                'line': 0,
                'issue': f'Error analyzing file: {e}',
                'code': ''
            })
        
        return security_issues

def analyze_project_structure(project_path: str) -> str:
    """åˆ†æé¡¹ç›®ç»“æ„"""
    try:
        analyzer = CodeAnalyzer(project_path)
        structure = analyzer.analyze_project_structure()
        
        result = f"ğŸ“Š é¡¹ç›®ç»“æ„åˆ†ææŠ¥å‘Š\n"
        result += f"{'='*50}\n\n"
        result += f"ğŸ“ æ€»æ–‡ä»¶æ•°: {structure['total_files']}\n"
        result += f"ğŸ“„ æ€»ä»£ç è¡Œæ•°: {structure['total_lines']}\n"
        result += f"ğŸ“‚ ç›®å½•æ•°: {len(structure['directories'])}\n\n"
        
        result += f"ğŸ”¤ è¯­è¨€ç»Ÿè®¡:\n"
        for ext, count in sorted(structure['language_stats'].items()):
            result += f"  {ext}: {count} ä¸ªæ–‡ä»¶\n"
        
        result += f"\nğŸ“‚ ç›®å½•ç»“æ„:\n"
        for directory in sorted(structure['directories']):
            result += f"  {directory}/\n"
        
        return result
        
    except Exception as e:
        return f"âŒ åˆ†æé¡¹ç›®ç»“æ„æ—¶å‡ºé”™: {e}"

def analyze_python_dependencies(project_path: str) -> str:
    """åˆ†æPythonä¾èµ–å…³ç³»"""
    try:
        analyzer = CodeAnalyzer(project_path)
        dependencies = analyzer.analyze_python_dependencies()
        
        result = f"ğŸ”— Pythonä¾èµ–å…³ç³»åˆ†æ\n"
        result += f"{'='*50}\n\n"
        
        for file_path, deps in dependencies.items():
            result += f"ğŸ“„ {file_path}:\n"
            for dep in deps:
                result += f"  â””â”€â”€ {dep}\n"
            result += "\n"
        
        return result
        
    except Exception as e:
        return f"âŒ åˆ†æä¾èµ–å…³ç³»æ—¶å‡ºé”™: {e}"

def analyze_code_quality(file_path: str) -> str:
    """åˆ†æä»£ç è´¨é‡"""
    try:
        analyzer = CodeAnalyzer(os.path.dirname(file_path))
        quality_report = analyzer.analyze_code_quality(file_path)
        
        result = f"ğŸ“Š ä»£ç è´¨é‡åˆ†ææŠ¥å‘Š\n"
        result += f"{'='*50}\n\n"
        result += f"ğŸ“„ æ–‡ä»¶: {quality_report['file']}\n\n"
        
        # æŒ‡æ ‡
        metrics = quality_report['metrics']
        result += f"ğŸ“ åŸºç¡€æŒ‡æ ‡:\n"
        result += f"  â€¢ ä»£ç è¡Œæ•°: {metrics['lines_of_code']}\n"
        result += f"  â€¢ ç©ºè¡Œæ•°: {metrics['empty_lines']}\n"
        result += f"  â€¢ æ³¨é‡Šè¡Œæ•°: {metrics['comment_lines']}\n"
        result += f"  â€¢ å¹³å‡è¡Œé•¿åº¦: {metrics['avg_line_length']:.1f}\n\n"
        
        # é—®é¢˜
        if quality_report['issues']:
            result += f"âŒ å‘ç°é—®é¢˜:\n"
            for issue in quality_report['issues']:
                result += f"  â€¢ {issue}\n"
            result += "\n"
        
        # å»ºè®®
        if quality_report['suggestions']:
            result += f"ğŸ’¡ æ”¹è¿›å»ºè®®:\n"
            for suggestion in quality_report['suggestions']:
                result += f"  â€¢ {suggestion}\n"
        
        return result
        
    except Exception as e:
        return f"âŒ åˆ†æä»£ç è´¨é‡æ—¶å‡ºé”™: {e}"

def find_security_issues(file_path: str) -> str:
    """æŸ¥æ‰¾å®‰å…¨é—®é¢˜"""
    try:
        analyzer = CodeAnalyzer(os.path.dirname(file_path))
        security_issues = analyzer.find_security_issues(file_path)
        
        result = f"ğŸ”’ å®‰å…¨é—®é¢˜åˆ†ææŠ¥å‘Š\n"
        result += f"{'='*50}\n\n"
        result += f"ğŸ“„ æ–‡ä»¶: {file_path}\n\n"
        
        if security_issues:
            result += f"âš ï¸  å‘ç° {len(security_issues)} ä¸ªæ½œåœ¨å®‰å…¨é—®é¢˜:\n\n"
            for issue in security_issues:
                result += f"  ğŸš¨ ç¬¬ {issue['line']} è¡Œ:\n"
                result += f"     é—®é¢˜: {issue['issue']}\n"
                result += f"     ä»£ç : {issue['code']}\n\n"
        else:
            result += f"âœ… æœªå‘ç°æ˜æ˜¾çš„å®‰å…¨é—®é¢˜\n"
        
        return result
        
    except Exception as e:
        return f"âŒ åˆ†æå®‰å…¨é—®é¢˜æ—¶å‡ºé”™: {e}" 