"""
æ–‡æ¡£ç®¡ç†å·¥å…·
æä¾›æ–‡æ¡£ç”Ÿæˆã€æœç´¢ã€è½¬æ¢ç­‰åŠŸèƒ½
"""

import os
import re
import json
from typing import Dict, List, Optional, Any
from collections import defaultdict
import subprocess

class DocumentManager:
    """æ–‡æ¡£ç®¡ç†å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = project_root
        self.doc_extensions = ['.md', '.txt', '.rst', '.adoc', '.html', '.pdf']
        self.code_extensions = ['.py', '.js', '.ts', '.java', '.cpp', '.c', '.go', '.rs', '.php']
        
    def find_documents(self) -> List[Dict[str, Any]]:
        """æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶"""
        documents = []
        
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡å¸¸è§çš„å¿½ç•¥ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv', 'env', 'build', 'dist']]
            
            for file in files:
                if file.startswith('.'):
                    continue
                    
                file_path = os.path.join(root, file)
                rel_path = os.path.relpath(file_path, self.project_root)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡æ¡£æ–‡ä»¶
                _, ext = os.path.splitext(file)
                if ext.lower() in self.doc_extensions:
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        documents.append({
                            'path': rel_path,
                            'name': file,
                            'extension': ext.lower(),
                            'size': os.path.getsize(file_path),
                            'lines': len(content.split('\n')),
                            'content': content
                        })
                    except Exception as e:
                        documents.append({
                            'path': rel_path,
                            'name': file,
                            'extension': ext.lower(),
                            'size': os.path.getsize(file_path),
                            'error': str(e)
                        })
        
        return documents
    
    def search_in_documents(self, query: str, case_sensitive: bool = False) -> List[Dict[str, Any]]:
        """åœ¨æ–‡æ¡£ä¸­æœç´¢å†…å®¹"""
        documents = self.find_documents()
        results = []
        
        flags = 0 if case_sensitive else re.IGNORECASE
        
        for doc in documents:
            if 'content' not in doc:
                continue
                
            content = doc['content']
            matches = []
            
            # æœç´¢åŒ¹é…é¡¹
            for i, line in enumerate(content.split('\n'), 1):
                if re.search(query, line, flags):
                    matches.append({
                        'line_number': i,
                        'line_content': line.strip(),
                        'match': re.search(query, line, flags).group(0)
                    })
            
            if matches:
                results.append({
                    'document': doc['path'],
                    'matches': matches,
                    'match_count': len(matches)
                })
        
        return results
    
    def generate_project_readme(self) -> str:
        """ç”Ÿæˆé¡¹ç›®README"""
        readme_content = []
        
        # é¡¹ç›®æ ‡é¢˜
        project_name = os.path.basename(os.path.abspath(self.project_root))
        readme_content.append(f"# {project_name}\n")
        
        # é¡¹ç›®ç»“æ„
        readme_content.append("## é¡¹ç›®ç»“æ„\n")
        readme_content.append("```")
        
        # ç”Ÿæˆç›®å½•æ ‘
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡éšè—ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv', 'env']]
            
            level = root.replace(self.project_root, '').count(os.sep)
            indent = '  ' * level
            folder_name = os.path.basename(root)
            if level == 0:
                readme_content.append(f"{project_name}/")
            else:
                readme_content.append(f"{indent}{folder_name}/")
            
            # æ·»åŠ æ–‡ä»¶
            subindent = '  ' * (level + 1)
            for file in files:
                if not file.startswith('.'):
                    readme_content.append(f"{subindent}{file}")
        
        readme_content.append("```\n")
        
        # æ–‡ä»¶ç»Ÿè®¡
        readme_content.append("## æ–‡ä»¶ç»Ÿè®¡\n")
        
        file_stats = defaultdict(int)
        total_files = 0
        total_lines = 0
        
        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv', 'env']]
            
            for file in files:
                if file.startswith('.'):
                    continue
                    
                file_path = os.path.join(root, file)
                _, ext = os.path.splitext(file)
                
                if ext:
                    file_stats[ext.lower()] += 1
                    total_files += 1
                    
                    # è®¡ç®—è¡Œæ•°
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            lines = len(f.readlines())
                            total_lines += lines
                    except:
                        pass
        
        readme_content.append(f"- æ€»æ–‡ä»¶æ•°: {total_files}")
        readme_content.append(f"- æ€»ä»£ç è¡Œæ•°: {total_lines}")
        readme_content.append("")
        
        # æŒ‰æ–‡ä»¶ç±»å‹ç»Ÿè®¡
        readme_content.append("### æ–‡ä»¶ç±»å‹ç»Ÿè®¡\n")
        for ext, count in sorted(file_stats.items()):
            readme_content.append(f"- {ext}: {count} ä¸ªæ–‡ä»¶")
        
        readme_content.append("")
        
        # æŸ¥æ‰¾ç°æœ‰æ–‡æ¡£
        documents = self.find_documents()
        if documents:
            readme_content.append("## æ–‡æ¡£æ–‡ä»¶\n")
            for doc in documents:
                readme_content.append(f"- [{doc['name']}]({doc['path']})")
        
        return '\n'.join(readme_content)
    
    def extract_api_documentation(self) -> Dict[str, Any]:
        """æå–APIæ–‡æ¡£"""
        api_docs = {
            'functions': [],
            'classes': [],
            'constants': []
        }
        
        # æŸ¥æ‰¾Pythonæ–‡ä»¶
        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'venv', 'env']]
            
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # æå–å‡½æ•°å’Œç±»
                        import ast
                        tree = ast.parse(content)
                        
                        for node in ast.walk(tree):
                            if isinstance(node, ast.FunctionDef):
                                api_docs['functions'].append({
                                    'name': node.name,
                                    'file': os.path.relpath(file_path, self.project_root),
                                    'line': node.lineno,
                                    'docstring': ast.get_docstring(node) or "æ— æ–‡æ¡£",
                                    'args': [arg.arg for arg in node.args.args]
                                })
                            elif isinstance(node, ast.ClassDef):
                                api_docs['classes'].append({
                                    'name': node.name,
                                    'file': os.path.relpath(file_path, self.project_root),
                                    'line': node.lineno,
                                    'docstring': ast.get_docstring(node) or "æ— æ–‡æ¡£"
                                })
                    except:
                        pass
        
        return api_docs

def find_all_documents(project_path: str = ".") -> str:
    """æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶"""
    try:
        doc_manager = DocumentManager(project_path)
        documents = doc_manager.find_documents()
        
        result = f"ğŸ“š æ–‡æ¡£æ–‡ä»¶åˆ—è¡¨\n"
        result += f"{'='*50}\n\n"
        
        if not documents:
            result += "æ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£æ–‡ä»¶\n"
            return result
        
        # æŒ‰ç±»å‹åˆ†ç»„
        docs_by_type = defaultdict(list)
        for doc in documents:
            docs_by_type[doc['extension']].append(doc)
        
        result += f"ğŸ“Š æ€»è®¡: {len(documents)} ä¸ªæ–‡æ¡£æ–‡ä»¶\n\n"
        
        for ext, docs in docs_by_type.items():
            result += f"ğŸ“„ {ext.upper()} æ–‡ä»¶ ({len(docs)} ä¸ª):\n"
            for doc in docs:
                size_kb = doc['size'] / 1024
                if 'lines' in doc:
                    result += f"  â€¢ {doc['path']} ({doc['lines']} è¡Œ, {size_kb:.1f}KB)\n"
                else:
                    result += f"  â€¢ {doc['path']} ({size_kb:.1f}KB)\n"
            result += "\n"
        
        return result
        
    except Exception as e:
        return f"âŒ æŸ¥æ‰¾æ–‡æ¡£æ—¶å‡ºé”™: {e}"

def search_in_documents(query: str, project_path: str = ".", case_sensitive: bool = False) -> str:
    """åœ¨æ–‡æ¡£ä¸­æœç´¢å†…å®¹"""
    try:
        doc_manager = DocumentManager(project_path)
        results = doc_manager.search_in_documents(query, case_sensitive)
        
        result = f"ğŸ” æ–‡æ¡£æœç´¢ç»“æœ\n"
        result += f"{'='*50}\n\n"
        result += f"ğŸ” æœç´¢å…³é”®è¯: {query}\n"
        result += f"ğŸ“ æœç´¢èŒƒå›´: {project_path}\n\n"
        
        if not results:
            result += "æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å†…å®¹\n"
            return result
        
        total_matches = sum(r['match_count'] for r in results)
        result += f"ğŸ“Š æ‰¾åˆ° {total_matches} ä¸ªåŒ¹é…é¡¹ï¼Œåˆ†å¸ƒåœ¨ {len(results)} ä¸ªæ–‡æ¡£ä¸­\n\n"
        
        for doc_result in results:
            result += f"ğŸ“„ {doc_result['document']} ({doc_result['match_count']} ä¸ªåŒ¹é…)\n"
            for match in doc_result['matches'][:5]:  # é™åˆ¶æ˜¾ç¤ºå‰5ä¸ªåŒ¹é…
                result += f"  ç¬¬ {match['line_number']} è¡Œ: {match['line_content']}\n"
            
            if doc_result['match_count'] > 5:
                result += f"  ... è¿˜æœ‰ {doc_result['match_count'] - 5} ä¸ªåŒ¹é…\n"
            result += "\n"
        
        return result
        
    except Exception as e:
        return f"âŒ æœç´¢æ–‡æ¡£æ—¶å‡ºé”™: {e}"

def generate_project_readme(project_path: str = ".") -> str:
    """ç”Ÿæˆé¡¹ç›®README"""
    try:
        doc_manager = DocumentManager(project_path)
        readme_content = doc_manager.generate_project_readme()
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        readme_path = os.path.join(project_path, "README_generated.md")
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        result = f"ğŸ“ é¡¹ç›®READMEå·²ç”Ÿæˆ\n"
        result += f"{'='*50}\n\n"
        result += f"ğŸ“„ æ–‡ä»¶è·¯å¾„: {readme_path}\n"
        result += f"ğŸ“ å†…å®¹é•¿åº¦: {len(readme_content)} å­—ç¬¦\n\n"
        result += "ğŸ“‹ READMEå†…å®¹é¢„è§ˆ:\n"
        result += "```markdown\n"
        result += readme_content[:500] + "...\n"
        result += "```\n"
        
        return result
        
    except Exception as e:
        return f"âŒ ç”ŸæˆREADMEæ—¶å‡ºé”™: {e}"

def extract_api_documentation(project_path: str = ".") -> str:
    """æå–APIæ–‡æ¡£"""
    try:
        doc_manager = DocumentManager(project_path)
        api_docs = doc_manager.extract_api_documentation()
        
        result = f"ğŸ“– APIæ–‡æ¡£æå–\n"
        result += f"{'='*50}\n\n"
        
        # å‡½æ•°ç»Ÿè®¡
        result += f"ğŸ”§ å‡½æ•°: {len(api_docs['functions'])} ä¸ª\n"
        result += f"ğŸ“¦ ç±»: {len(api_docs['classes'])} ä¸ª\n\n"
        
        # å‡½æ•°åˆ—è¡¨
        if api_docs['functions']:
            result += "ğŸ”§ å‡½æ•°åˆ—è¡¨:\n"
            for func in api_docs['functions']:
                result += f"  â€¢ {func['name']}({', '.join(func['args'])})\n"
                result += f"    æ–‡ä»¶: {func['file']}:{func['line']}\n"
                result += f"    è¯´æ˜: {func['docstring'][:100]}...\n\n"
        
        # ç±»åˆ—è¡¨
        if api_docs['classes']:
            result += "ğŸ“¦ ç±»åˆ—è¡¨:\n"
            for cls in api_docs['classes']:
                result += f"  â€¢ {cls['name']}\n"
                result += f"    æ–‡ä»¶: {cls['file']}:{cls['line']}\n"
                result += f"    è¯´æ˜: {cls['docstring'][:100]}...\n\n"
        
        return result
        
    except Exception as e:
        return f"âŒ æå–APIæ–‡æ¡£æ—¶å‡ºé”™: {e}"

def search_code_patterns(pattern: str, project_path: str = ".") -> str:
    """æœç´¢ä»£ç æ¨¡å¼"""
    try:
        results = []
        
        for root, dirs, files in os.walk(project_path):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv', 'env']]
            
            for file in files:
                if file.startswith('.'):
                    continue
                    
                file_path = os.path.join(root, file)
                _, ext = os.path.splitext(file)
                
                # åªæœç´¢ä»£ç æ–‡ä»¶
                if ext.lower() in ['.py', '.js', '.ts', '.java', '.cpp', '.c', '.go', '.rs', '.php']:
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        matches = []
                        for i, line in enumerate(content.split('\n'), 1):
                            if re.search(pattern, line, re.IGNORECASE):
                                matches.append({
                                    'line_number': i,
                                    'line_content': line.strip()
                                })
                        
                        if matches:
                            results.append({
                                'file': os.path.relpath(file_path, project_path),
                                'matches': matches,
                                'match_count': len(matches)
                            })
                    except:
                        pass
        
        result = f"ğŸ” ä»£ç æ¨¡å¼æœç´¢\n"
        result += f"{'='*50}\n\n"
        result += f"ğŸ” æœç´¢æ¨¡å¼: {pattern}\n"
        result += f"ğŸ“ æœç´¢èŒƒå›´: {project_path}\n\n"
        
        if not results:
            result += "æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„ä»£ç æ¨¡å¼\n"
            return result
        
        total_matches = sum(r['match_count'] for r in results)
        result += f"ğŸ“Š æ‰¾åˆ° {total_matches} ä¸ªåŒ¹é…é¡¹ï¼Œåˆ†å¸ƒåœ¨ {len(results)} ä¸ªæ–‡ä»¶ä¸­\n\n"
        
        for file_result in results:
            result += f"ğŸ“„ {file_result['file']} ({file_result['match_count']} ä¸ªåŒ¹é…)\n"
            for match in file_result['matches'][:3]:  # é™åˆ¶æ˜¾ç¤ºå‰3ä¸ªåŒ¹é…
                result += f"  ç¬¬ {match['line_number']} è¡Œ: {match['line_content']}\n"
            
            if file_result['match_count'] > 3:
                result += f"  ... è¿˜æœ‰ {file_result['match_count'] - 3} ä¸ªåŒ¹é…\n"
            result += "\n"
        
        return result
        
    except Exception as e:
        return f"âŒ æœç´¢ä»£ç æ¨¡å¼æ—¶å‡ºé”™: {e}" 